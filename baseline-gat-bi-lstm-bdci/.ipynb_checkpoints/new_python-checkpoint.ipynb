{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (3823436381.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 60\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.eval()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "    geohasd_df_dict = {}\n",
    "    date_df_dict = {}\n",
    "    number_hash = 0\n",
    "    number_date = 0\n",
    "    for i in df[\"geohash_id\"]:\n",
    "\n",
    "        if i not in geohasd_df_dict.keys():\n",
    "            geohasd_df_dict[i] = number_hash\n",
    "            number_hash += 1\n",
    "\n",
    "    for i in df[\"date_id\"]:\n",
    "        if i not in date_df_dict.keys():\n",
    "            date_df_dict[i] = number_date\n",
    "            number_date += 1\n",
    "\n",
    "    # new_data 的二维列表。它的大小是 len(date_df_dict) 行乘以 len(geohasd_df_dict) 列。\n",
    "    # 具体地，代码首先使用 geohasd_df_dict 将地理哈希编码转换为 new_data 的列索引，\n",
    "    # 使用 date_df_dict 将日期转换为 new_data 的行索引，\n",
    "    # 然后将新数据填入 new_data 对应位置的单元格中。\n",
    "    # 这可以使用两个索引进行操作：date_index （行）和 hash_index （列），\n",
    "    # 它们是通过哈希表存储的，因此读取非常快。\n",
    "    new_data = [len(geohasd_df_dict) * [0]] * len(date_df_dict)\n",
    "    for index, row in df.iterrows():\n",
    "        # print(index)\n",
    "        hash_index, date_index = geohasd_df_dict[row[\"geohash_id\"]], date_df_dict[row[\"date_id\"]]\n",
    "        #将时间index加到里面\n",
    "\n",
    "        new_data[date_index][hash_index] = [date_index]+list(row.iloc[2:])\n",
    "    new_data = np.array(new_data)\n",
    "    # x_train,y_train = new_data[:, :-2], new_data[:, -2:]\n",
    "    # print(len(geohasd_df_dict))\n",
    "    # exit()\n",
    "    # print(x_train.shape)\n",
    "    # print(y_train.shape)\n",
    "    #这里构建邻接矩阵其中mask表示1为有边，0无边， value_mask表示有值\n",
    "    #并且这里我考虑mask是一个无向图，如果有向删除x_mask[date_index][point2_index][point1_index],value_mask同理\n",
    "   \n",
    "    x_mask =  np.zeros((len(date_df_dict),len(geohasd_df_dict),len(geohasd_df_dict),1), dtype = float)\n",
    "    x_edge_df =np.zeros((len(date_df_dict),len(geohasd_df_dict),len(geohasd_df_dict),2), dtype = float)\n",
    "\n",
    "    for index, row in edge_df.iterrows():\n",
    "        # print(index)\n",
    "        if row[\"geohash6_point1\"] not in geohasd_df_dict.keys() or row[\"geohash6_point2\"] not in geohasd_df_dict.keys():\n",
    "            continue\n",
    "        point1_index,point2_index,F_1,F_2,date_index= geohasd_df_dict[row[\"geohash6_point1\"]],geohasd_df_dict[row[\"geohash6_point2\"]]\\\n",
    "            ,row[\"F_1\"],row[\"F_2\"],date_df_dict[row[\"date_id\"]]\n",
    "        \n",
    "        # 将 x_mask 中对应位置的值设为1，表示该位置存在边。\n",
    "        x_mask[date_index][point1_index][point2_index] = 1\n",
    "        x_mask[date_index][point2_index][point1_index] = 1\n",
    "\n",
    "        # 同时，将 x_edge_df 中对应位置的值设为 [F_1, F_2]，即该位置的特征向量。\n",
    "        x_edge_df[date_index][point1_index][point2_index] =  [F_1,F_2]\n",
    "        x_edge_df[date_index][point2_index][point1_index] = [F_1, F_2]\n",
    "    # print(data)\n",
    "\n",
    "    return     geohasd_df_dict, date_df_dict, new_data,x_mask, x_edge_df\n",
    "\n",
    "def eval(model, dataset, args):\n",
    "        model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        dev_loss = 0.0\n",
    "        for j in trange(dataset.batch_count):\n",
    "            x_date, x_feature, x_mask_data, x_edge_data, x_tags = dataset.get_batch(j)\n",
    "            act_pre, con_pre = model(x_date, x_feature, x_mask_data)\n",
    "            predict = torch.cat((act_pre, con_pre), dim=-1)\n",
    "            loss = criterion(predict, x_tags)\n",
    "            dev_loss+= loss\n",
    "        print(\"this epoch dev loss is {}\".format(dev_loss))\n",
    "        model.train()\n",
    "\n",
    "\n",
    "def train(args):\n",
    "\n",
    "    #使用get_train_data函数获取训练数据和标签。\n",
    "    geohasd_df_dict, date_df_dict, x_train, x_mask, x_edge_df = get_train_data('./train_90.csv',\n",
    "                                                                                        \"./edge_90.csv\")\n",
    "    #分割各种训练集测试集\n",
    "    x_train,x_dev = torch.tensor(x_train[:int(len(x_train)*args.rat)]),torch.tensor(x_train[int(len(x_train)*args.rat):])\n",
    "    x_mask_train,x_mask_dev = torch.tensor(x_mask[:int(len(x_mask)*args.rat)]),torch.tensor(x_mask[int(len(x_mask)*args.rat):])\n",
    "    x_edge_train, x_edge_dev = torch.tensor(x_edge_df[:int(len(x_edge_df) * args.rat)]),torch.tensor( x_edge_df[int(len(x_edge_df) * args.rat):])\n",
    "\n",
    "\n",
    "\n",
    "    date_emb = 5\n",
    "     # 这里的x包含了date_id+F35个特征+2个y值的\n",
    "    # train_activate = torch.tensor(y_train[:, -2])\n",
    "    # train_consume = torch.tensor(y_train[:, -1])\n",
    "\n",
    "\n",
    "    # rmse_loss = torch.sqrt(mse_loss)\n",
    "\n",
    "    #定义模型并将其移动到指定设备上。\n",
    "    model = my_model.GAT(date_emb =[len(date_df_dict),date_emb], nfeat=35, nhid=64, dropout=0.3, alpha=0.3, nheads=8).to(args.device)\n",
    "    # model = my_model.BILSTM(date_emb =[len(date_df_dict),date_emb], nfeat=35, nhid=64, dropout=0.3, alpha=0.3, nheads=8).to(args.device)\n",
    "    \n",
    "    #定义优化器（使用Adam算法）和损失函数（criterion）\n",
    "    optimizer = torch.optim.Adam(params=model.parameters(),lr=args.lr)\n",
    "    # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, args.decline, gamma=0.5, last_epoch=-1)\n",
    "    model.train()\n",
    "\n",
    "    #创建训练集和验证集的数据迭代器。\n",
    "    trainset = data.DataIterator(x_train,x_mask_train,x_edge_train, args)\n",
    "    valset =data.DataIterator(x_dev,x_mask_dev,x_edge_dev, args)\n",
    "    for indx in range(args.epochs):\n",
    "        train_all_loss = 0.0\n",
    "        for j in trange(trainset.batch_count):\n",
    "            #获取当前batch的数据（日期、特征、掩码、边缘数据和标签）\n",
    "            x_date,x_feature,x_mask_data,x_edge_data,x_tags= trainset.get_batch(j)\n",
    "            act_pre, con_pre = model(x_date,x_feature,x_mask_data)\n",
    "            predict = torch.cat((act_pre, con_pre), dim=-1)\n",
    "\n",
    "            #计算预测结果和标签之间的损失。\n",
    "            loss = criterion(predict, x_tags)\n",
    "            train_all_loss += loss\n",
    "\n",
    "            #清除优化器的梯度。\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #反向传播并更新模型的参数。\n",
    "            loss.backward()\n",
    "        optimizer.step()\n",
    "        print('this epoch train loss :{0}'.format(train_all_loss))\n",
    "        # scheduler.step()\n",
    "\n",
    "        #调用eval函数对验证集进行评估。\n",
    "        eval(model,valset, args)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--epochs', type=int, default=300,\n",
    "                        help='training epoch number')\n",
    "    parser.add_argument('--batch_size', type=int, default=4,\n",
    "                        help='batch_size')\n",
    "    parser.add_argument('--device', type=str, default=\"cuda\",\n",
    "                        help='gpu or cpu')\n",
    "    parser.add_argument('--lr', type=float, default=1e-3,\n",
    "                        )\n",
    "    parser.add_argument('--rat', type=float, default=0.9,)\n",
    "\n",
    "    parser.add_argument('--decline', type=int, default=30, help=\"number of epochs to decline\")\n",
    "    train(parser.parse_args())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# gcn = GCN(n_features=51, hidden_dim=64, dropout=0.3, n_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# date_node = np.concatenate([sample.iloc[:, 2:37].values, date_embed], axis=1)\n",
    "# date_node.shape\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# adj = torch.randn(90, 90)\n",
    "# x_node = torch.from_numpy(date_node).type_as(adj)\n",
    "# predict = gcn(x_node, adj)\n",
    "# predict.shape, predict\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# gat = GAT(nfeat=51, nhid=64, nclass=2, dropout=0.3, alpha=0.3, nheads=8)\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# adj = torch.randn(90, 90)\n",
    "# x_node = torch.from_numpy(date_node).type_as(adj)\n",
    "# predict = gat(x_node, adj)\n",
    "# predict.shape, predict\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# actual_values = sample.iloc[:, 37:]  # active_index，consume_index\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "#\n",
    "# # 定义预测值和实际观测值\n",
    "# actual_values = torch.from_numpy(sample.iloc[:, 37:].values)  # 实际观测值\n",
    "#\n",
    "# # 计算RMSE损失\n",
    "# criterion = nn.MSELoss()  # 使用均方误差损失函数计算MSE\n",
    "# mse_loss = criterion(predict, actual_values)\n",
    "# rmse_loss = torch.sqrt(mse_loss)\n",
    "#\n",
    "# # 打印RMSE损失\n",
    "# print(\"RMSE Loss:\", rmse_loss.item())\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# x_node, adj\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# import pandas as pd\n",
    "#\n",
    "# # 读取CSV文件\n",
    "# edge = pd.read_csv('./edge_90.csv')\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# edge.head()\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# geohash_id = df.geohash_id\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# geohash_id.head()\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# align = edge[(edge['geohash6_point1'] == df.geohash_id[0]) & (edge['date_id'] == df.date_id[0])]\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# align\n",
    "#\n",
    "# # %%\n",
    "#\n",
    "# df.geohash_id.drop_duplicates()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
